# Clasificaci√≥n de Titulares de Noticias usando Redes Convolucionales y EDA: Un Enfoque Basado en CNN y Synonym Replacement


Damariz Licea

## Abstract
Este trabajo presenta un enfoque para la clasificaci√≥n de titulares de noticias mediante una red neuronal convolucional (CNN), complementado con t√©cnicas de aumento de datos basadas en sin√≥nimos a trav√©s de WordNet. Utilizando el "News Category Dataset", el proyecto abarca desde la limpieza de texto hasta la evaluaci√≥n del modelo, implementando procesos de tokenizaci√≥n, embeddings y convoluciones, con m√©tricas transparentes para el investigador. Como mejora, el modelo incorpora early stopping y checkpoints para optimizar su rendimiento. La evaluaci√≥n del desempe√±o se realiz√≥ mediante una matriz de confusi√≥n y m√©tricas como precisi√≥n, recall y f1-score por clase, junto con la accuracy global, utilizando la funci√≥n classification_report de sklearn. Esta investigaci√≥n se fundamenta en trabajos previos sobre CNN para texto (Kim, 2014) y t√©cnicas de aumento de datos, espec√≠ficamente aplicando la estrategia EDA (Easy Data Augmentation) de Wei y Zou (2019) para el reemplazo de palabras por sin√≥nimos, demostrando que modelos relativamente simples pueden lograr resultados efectivos con estrategias de procesamiento adecuadas.

## Introducci√≥n

### Clasificaci√≥n de Titulares de Noticias
La clasificaci√≥n autom√°tica de texto constituye una tarea fundamental en el procesamiento del lenguaje natural (NLP). Los titulares de noticias representan un desaf√≠o particular para esta clasificaci√≥n debido a su brevedad y a la informaci√≥n altamente condensada que contienen. A diferencia de los art√≠culos completos, los titulares ofrecen contexto limitado, lo que requiere modelos capaces de captar informaci√≥n esencial en pocas palabras.
Para este estudio se utiliz√≥ el "News Category Dataset" de Kaggle, una colecci√≥n de aproximadamente 200,000 art√≠culos de noticias con sus respectivos titulares, publicados por HuffPost entre 2012 y 2018. Este conjunto de datos contiene art√≠culos en ingl√©s clasificados en diversas categor√≠as como "POLITICS", "WELLNESS", "ENTERTAINMENT", "TRAVEL", entre otras.
El dataset est√° estructurado en formato JSON, donde cada registro incluye varios campos como t√≠tulo, enlace, categor√≠a, descripci√≥n corta y fecha de publicaci√≥n. Para los prop√≥sitos de esta investigaci√≥n, se utilizaron exclusivamente los campos "headline" (titular) y "category" (categor√≠a), ya que el objetivo principal es predecir la categor√≠a de una noticia bas√°ndose √∫nicamente en su titular.


La elecci√≥n de este dataset responde a tres criterios fundamentales:

Presenta una amplia diversidad de categor√≠as, lo que incrementa la complejidad de la tarea de clasificaci√≥n.
Los titulares son concisos pero informativos, lo que los convierte en candidatos ideales para evaluar la capacidad del modelo de extraer informaci√≥n relevante de textos breves.
Contiene una cantidad sustancial de datos, lo que contrasta favorablemente con experiencias previas en la clasificaci√≥n de im√°genes de mariposas mediante CNNs, un aspecto que se abordar√° posteriormente.

### Fundamento Te√≥rico
Este trabajo se fundamenta en la investigaci√≥n de Kim (2014) titulada "Convolutional Neural Networks for Sentence Classification". En dicho estudio, Kim demuestra que las redes neuronales convolucionales (CNN), tradicionalmente aplicadas al procesamiento de im√°genes, pueden adaptarse eficazmente para clasificar textos con resultados notables, detectando patrones significativos en secuencias de palabras.

Seg√∫n Kim, una CNN dise√±ada para clasificaci√≥n textual debe incorporar:

Una capa de embedding que transforma palabras en vectores num√©ricos
Filtros convolucionales que identifican patrones locales (como frases o expresiones)
Una capa de pooling que selecciona las caracter√≠sticas m√°s relevantes
Capas densas para la clasificaci√≥n final

En el modelo implementado para este estudio se utilizan:

Embeddings de dimensi√≥n 128
Filtros convolucionales de tama√±o 5
GlobalMaxPooling1D para reducir dimensionalidad, evitar sobreajuste y destacar la caracter√≠stica m√°s relevante detectada por cada filtro, independientemente de su posici√≥n en la secuencia
Dropout (0.5) para prevenir el sobreajuste, siguiendo las recomendaciones de Kim

### T√©cnicas de Aumento de Datos 
Para enriquecer las oportunidades de aprendizaje del modelo, se implementaron t√©cnicas de aumento de datos textuales basadas en el trabajo de Wei y Zou (2019) "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks". Estos investigadores proponen cuatro t√©cnicas sencillas para la generaci√≥n de datos adicionales: reemplazo por sin√≥nimos, inserci√≥n aleatoria, intercambio aleatorio y eliminaci√≥n aleatoria.
Para este estudio, se opt√≥ espec√≠ficamente por la t√©cnica de reemplazo por sin√≥nimos utilizando WordNet, una exhaustiva base de datos l√©xica del ingl√©s. Esta t√©cnica sustituye determinadas palabras en un texto por sus sin√≥nimos correspondientes. De acuerdo con Wei y Zou, el n√∫mero de palabras a reemplazar se determina mediante un par√°metro Œ± multiplicado por la longitud del texto. Este m√©todo preserva el significado esencial del contenido mientras genera variaciones que contribuyen a mejorar la capacidad de generalizaci√≥n del modelo.
Wei y Zou demostraron que estas t√©cnicas resultan particularmente beneficiosas en escenarios con datos limitados, mejorando significativamente la precisi√≥n en diversos conjuntos de datos. En el contexto de esta investigaci√≥n, se estableci√≥ Œ± = 0.1, lo que implica el reemplazo de aproximadamente el 10% de las palabras en cada titular.


## Metodolog√≠a
El desarrollo de este proyecto sigui√≥ una secuencia estructurada de pasos que abarcan desde el preprocesamiento de datos hasta la evaluaci√≥n del modelo. A continuaci√≥n, se detalla cada fase del proceso metodol√≥gico implementado.
Preprocesamiento de Datos
Limpieza de Texto
Se aplicaron t√©cnicas est√°ndar de limpieza textual a todos los titulares:

Conversi√≥n a min√∫sculas para uniformidad
Eliminaci√≥n de signos de puntuaci√≥n
Normalizaci√≥n de espacios para eliminar duplicaciones

Codificaci√≥n de Categor√≠as
Las categor√≠as textuales fueron transformadas a representaciones num√©ricas mediante un mapeo sistem√°tico de cada categor√≠a a un √≠ndice espec√≠fico, facilitando su procesamiento por el modelo.
Aumento de Datos
Se implement√≥ la t√©cnica EDA (Easy Data Augmentation), espec√≠ficamente el reemplazo por sin√≥nimos utilizando WordNet, para enriquecer el conjunto de datos y mejorar la capacidad de generalizaci√≥n del modelo.
Divisi√≥n de Datos
El conjunto de datos fue segmentado en tres subconjuntos:

Entrenamiento: 64% de los datos
Validaci√≥n: 16% de los datos
Prueba: 20% de los datos

Se utiliz√≥ la estratificaci√≥n (stratify) para preservar la distribuci√≥n proporcional de las clases en cada subconjunto.
Tokenizaci√≥n y Padding
Los titulares fueron convertidos en secuencias num√©ricas mediante tokenizaci√≥n, y posteriormente se aplic√≥ padding para asegurar que todas las secuencias tuvieran la misma longitud, requisito necesario para su procesamiento en la red neuronal.
Arquitectura del Modelo
Siguiendo el enfoque propuesto por Kim (2014), se implement√≥ una red neuronal convolucional especializada para la clasificaci√≥n de texto. La arquitectura del modelo incluye las siguientes capas:

Capa de Embedding: Transforma los √≠ndices de palabras en vectores densos de 128 dimensiones, creando representaciones num√©ricas significativas del texto.
Capa Convolucional 1D: Aplica 128 filtros de tama√±o 5 para la detecci√≥n de patrones ling√º√≠sticos en secuencias de palabras, identificando caracter√≠sticas relevantes.
GlobalMaxPooling1D: Extrae la caracter√≠stica m√°s prominente detectada por cada filtro, reduciendo la dimensionalidad y preservando la informaci√≥n m√°s relevante.
Dropout (0.5): Implementa una t√©cnica de regularizaci√≥n que desactiva aleatoriamente el 50% de las neuronas durante el entrenamiento, previniendo el sobreajuste.
Capa Densa: Procesa las caracter√≠sticas extra√≠das mediante 128 neuronas con funci√≥n de activaci√≥n ReLU, permitiendo el modelado de relaciones no lineales complejas.
Capa de Salida: Presenta una neurona por cada categor√≠a con funci√≥n de activaci√≥n softmax, generando distribuciones de probabilidad sobre las posibles clasificaciones.

Configuraci√≥n del Entrenamiento
El proceso de entrenamiento del modelo fue configurado con los siguientes par√°metros y t√©cnicas:

Funci√≥n de p√©rdida: Se utiliz√≥ sparse_categorical_crossentropy, una funci√≥n apropiada para problemas de clasificaci√≥n multiclase cuando las etiquetas est√°n codificadas como enteros.
Optimizador: Se implement√≥ Adam, un algoritmo de optimizaci√≥n que adapta autom√°ticamente la tasa de aprendizaje durante el entrenamiento.
M√©trica de evaluaci√≥n: Se emple√≥ Accuracy para cuantificar la proporci√≥n de predicciones correctas realizadas por el modelo.
Early Stopping: Se incorpor√≥ un mecanismo para detener autom√°ticamente el entrenamiento cuando no se observa mejora en la p√©rdida de validaci√≥n durante 3 √©pocas consecutivas, evitando el sobreajuste.
Model Checkpoint: Se configur√≥ un sistema para guardar la versi√≥n del modelo que presenta la mejor precisi√≥n en el conjunto de validaci√≥n, asegurando la conservaci√≥n del modelo √≥ptimo.
Batch size: Se definieron lotes de 32 muestras para actualizar los pesos del modelo durante el entrenamiento.
√âpocas: Se entren√≥ por m√°ximo de 400 episodios.

## Evaluaci√≥n del Modelo
M√©tricas de Evaluaci√≥n
Para evaluar exhaustivamente el desempe√±o del modelo, se implement√≥ un conjunto diverso de m√©tricas y visualizaciones que permiten analizar su comportamiento tanto a nivel global como por clase individual:
Matriz de Confusi√≥n
Se emple√≥ una matriz de confusi√≥n para visualizar la distribuci√≥n de predicciones correctas e incorrectas para cada categor√≠a, proporcionando una representaci√≥n gr√°fica intuitiva del rendimiento del clasificador.
M√©tricas por Clase
Para cada categor√≠a del modelo, se calcularon las siguientes m√©tricas:
Precision (Precisi√≥n)
La precisi√≥n mide qu√© tan exactas son las predicciones positivas del modelo. Representa la proporci√≥n de elementos correctamente clasificados en una categor√≠a respecto al total de elementos asignados a dicha categor√≠a. Esta m√©trica es particularmente relevante en contextos donde el costo de los falsos positivos es elevado.
$\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$
Recall (Exhaustividad)
El recall mide qu√© tan completa es la detecci√≥n de positivos del modelo. Indica la proporci√≥n de elementos correctamente identificados como pertenecientes a una categor√≠a respecto al total de elementos que realmente pertenecen a dicha categor√≠a. Esta m√©trica adquiere especial importancia cuando el costo asociado a los falsos negativos es alto.
$\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$
F1-Score
El F1-Score representa la media arm√≥nica de precisi√≥n y recall, proporcionando un √∫nico valor que equilibra ambas m√©tricas. Este indicador resulta especialmente √∫til cuando se busca un balance entre precisi√≥n y recall, particularmente en conjuntos de datos con distribuciones de clase desequilibradas, donde la exactitud global puede resultar enga√±osa.
$\text{F1-Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$
Se opt√≥ por utilizar el F1-Score como complemento a las m√©tricas individuales para obtener una evaluaci√≥n m√°s robusta y equilibrada del desempe√±o del modelo.
Interpretaci√≥n de M√©tricas Combinadas
La combinaci√≥n de precision y recall permite interpretar el comportamiento del modelo seg√∫n el siguiente esquema:

Alta precisi√≥n, bajo recall: El modelo adopta un enfoque conservador. Cuando predice una clase, suele acertar, pero omite muchos casos positivos.
Baja precisi√≥n, alto recall: El modelo adopta un enfoque liberal. Identifica la mayor√≠a de los casos positivos, pero tambi√©n clasifica err√≥neamente muchos negativos como positivos.
Alta precisi√≥n, alto recall: El modelo exhibe un excelente rendimiento. Identifica la mayor√≠a de los positivos con pocos falsos positivos.
Baja precisi√≥n, bajo recall: El modelo presenta deficiencias significativas para esa clase espec√≠fica.

Accuracy Global
Adem√°s de las m√©tricas por clase, se monitoriz√≥ la exactitud (accuracy) global del modelo, que representa la proporci√≥n total de predicciones correctas respecto al total de predicciones realizadas.
Resultados de la Evaluaci√≥n
Las visualizaciones generadas durante el proceso de evaluaci√≥n revelaron informaci√≥n valiosa sobre el desempe√±o del modelo:
Mostrar imagen
M√©tricas por cada clase analizada, mostrando solo algunas clases representativas.
Mostrar imagen
Evoluci√≥n del accuracy y loss global del modelo durante una ejecuci√≥n de 5 episodios.
Mostrar imagen
Matriz de confusi√≥n implementada utilizando sklearn.
El an√°lisis de los resultados indica que el modelo alcanz√≥ una precisi√≥n media de 0.57, un recall medio de 0.48, y un F1-Score medio de 0.51. Estos valores sugieren que el modelo presenta un desempe√±o equilibrado, donde la precisi√≥n ligeramente superior al recall indica una tendencia moderadamente conservadora en sus predicciones, con un F1-Score que refleja un balance razonable entre ambas m√©tricas.
Mostrar imagen
Resumen de clasificaci√≥n con n√∫mero de aciertos correctos e incorrectos.
Mostrar imagen
Matriz detallada de falsos positivos, falsos negativos, verdaderos positivos y verdaderos negativos.
El modelo alcanz√≥ un accuracy global m√°ximo de 0.8 en el conjunto de validaci√≥n durante una ejecuci√≥n de 30 epochs.
Funcionalidad de Predicci√≥n
Como complemento a la evaluaci√≥n cuantitativa, se implement√≥ una funci√≥n interactiva que permite a los usuarios ingresar un titular de noticia o texto breve arbitrario, para que el modelo realice una predicci√≥n sobre la categor√≠a a la que pertenecer√≠a. Esta funcionalidad proporciona una demostraci√≥n pr√°ctica de la aplicabilidad del modelo en escenarios reales, adem√°s de ofrecer una forma intuitiva de evaluar cualitativamente su desempe√±o.

## # Resultados

## Evaluaci√≥n del Desempe√±o General

El objetivo inicial de este proyecto no contemplaba alcanzar un umbral espec√≠fico de precisi√≥n, sino m√°s bien explorar si una implementaci√≥n basada en la arquitectura propuesta por Kim (2014) podr√≠a resolver efectivamente la clasificaci√≥n de titulares de noticias. En t√©rminos cuantitativos, se estableci√≥ como criterio m√≠nimo de √©xito superar un nivel de certeza del 50%.

Los resultados obtenidos confirman que el modelo implementado logr√≥ superar ampliamente este umbral, alcanzando un accuracy global m√°ximo de 0.8 en el conjunto de validaci√≥n durante una ejecuci√≥n extendida a 30 epochs. Este nivel de desempe√±o demuestra que, incluso con una arquitectura relativamente simple, las redes neuronales convolucionales pueden capturar eficazmente los patrones ling√º√≠sticos presentes en textos breves como los titulares de noticias.

## Demostraci√≥n Pr√°ctica: Predicci√≥n Interactiva

Para ilustrar la aplicabilidad pr√°ctica del modelo, se implement√≥ una funci√≥n de predicci√≥n interactiva que permite evaluar su desempe√±o con nuevos titulares. A modo de ejemplo, se prob√≥ el titular ficticio: "Korean beauty company causes acne", ante el cual el modelo asign√≥ la categor√≠a "Style & Beauty" con una confianza aproximada del 87%.

![Predicci√≥n interactiva](figura_prediccion.png)
*Interfaz de predicci√≥n interactiva mostrando la clasificaci√≥n del titular ejemplo con su correspondiente nivel de confianza.*

Esta elevada confianza en la predicci√≥n sugiere que el modelo ha logrado identificar correctamente los elementos sem√°nticos asociados a la categor√≠a de belleza, demostrando su capacidad para generalizar a partir de los patrones aprendidos durante el entrenamiento.

## Cambio de Enfoque: Del Procesamiento de Im√°genes al Procesamiento de Texto

### Dificultades con la Clasificaci√≥n de Im√°genes

Es importante destacar que la direcci√≥n actual del proyecto surgi√≥ como respuesta a los desaf√≠os encontrados en un enfoque previo. Inicialmente, el objetivo era desarrollar un clasificador de im√°genes de mariposas por especie utilizando redes neuronales convolucionales tradicionales.

Para este prop√≥sito, se utiliz√≥ el dataset "Butterfly Classification" de Kaggle. Sin embargo, desde las primeras etapas de implementaci√≥n, se detectaron varios problemas fundamentales:

1. **Desbalance significativo del dataset**: El modelo mostraba una clara tendencia a favorecer las clases con mayor representaci√≥n en el conjunto de datos.

2. **Limitaciones del aumento de datos**: A pesar de implementar t√©cnicas de jitter para enriquecer la diversidad de las im√°genes, estas intervenciones resultaron insuficientes para mitigar el problema del desbalance.

3. **Arquitecturas avanzadas sin mejora significativa**: La reimplementaci√≥n del modelo utilizando la arquitectura InceptionV3 no produjo mejoras sustanciales en el rendimiento.

4. **Estancamiento en el aprendizaje**: A pesar de un entrenamiento prolongado con numerosos episodios, el accuracy global nunca super√≥ el umbral del 0.2, lo que suger√≠a que el modelo podr√≠a estar memorizando en lugar de aprendiendo patrones generalizables.

Esta situaci√≥n es consistente con experiencias previas en aprendizaje por refuerzo, donde se ha observado que extender el entrenamiento no compensa las deficiencias fundamentales en la configuraci√≥n del modelo o en la calidad de los datos. Por el contrario, un entrenamiento prolongado en estas circunstancias puede resultar contraproducente, llevando al modelo a aprender asociaciones incorrectas.

### Transici√≥n al Procesamiento de Texto

La transici√≥n al dataset de noticias y la implementaci√≥n del enfoque actual represent√≥ un cambio estrat√©gico que result√≥ en mejoras significativas en los resultados obtenidos. Esta experiencia refuerza la importancia de:

1. Seleccionar datasets con distribuciones balanceadas o implementar t√©cnicas efectivas para compensar los desbalances.
2. Reconocer cu√°ndo un enfoque no est√° produciendo resultados satisfactorios y considerar alternativas.
3. Aprovechar la transferencia de conocimiento entre dominios, adaptando arquitecturas probadas como la propuesta por Kim para resolver problemas espec√≠ficos.

La evidencia del trabajo previo con im√°genes de mariposas se encuentra documentada como referencia complementaria a este estudio, proporcionando un valioso contraste metodol√≥gico y contextual.

## Conclusiones
Este proyecto demuestra que una arquitectura CNN simple, como la propuesta por Kim (2014), sigue siendo efectiva para tareas de clasificaci√≥n de texto, incluso con entradas tan breves como los titulares de noticias. Aplicando t√©cnicas de limpieza adecuadas y un ligero aumento de datos, es posible alcanzar un rendimiento satisfactorio. En resumen, menos puede ser m√°s cuando se aplica de forma correcta.

## Referencias

1. Kim, Y. (2014). *Convolutional Neural Networks for Sentence Classification*. arXiv preprint arXiv:1408.5882. [https://arxiv.org/abs/1408.5882](https://arxiv.org/abs/1408.5882)

2. Wei, J., & Zou, K. (2019). *EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks*. arXiv preprint arXiv:1901.11196. [https://arxiv.org/abs/1901.11196](https://arxiv.org/abs/1901.11196)

3. News Category Dataset on Kaggle: [https://www.kaggle.com/datasets/rmisra/news-category-dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset)

4. Bird, S., Klein, E., & Loper, E. (2009). *Natural Language Processing with Python*. O'Reilly Media. (Referencia para el uso de WordNet mediante NLTK)

5. Scikit-learn: Pedregosa, F., et al. (2011). *Scikit-learn: Machine Learning in Python*. Journal of Machine Learning Research, 12, 2825‚Äì2830. [https://jmlr.org/papers/v12/pedregosa11a.html](https://jmlr.org/papers/v12/pedregosa11a.html)



# Archivado, se queda para evidencia de trabajo, por favor no leer a partir de aqu√≠.
# Butterfly Classification
# V1 ‚Äî Semana del 31 de marzo al 4 de abril
## Elecci√≥n del Dataset

Eleg√≠ el dataset Butterfly Image Classification disponible en Kaggle:
üîó https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification

La tem√°tica me pareci√≥ interesante y atractiva, asum√≠ que las mariposas se diferenciaban principalmente por color, lo que podr√≠a facilitar la clasificaci√≥n. Adem√°s, el dataset cuenta con buenas rese√±as de usabilidad en la plataforma.

Decid√≠ trabajar en Google Colab por la facilidad que ofrece en compatibilidad de librer√≠as y por su mayor capacidad de c√≥mputo en comparaci√≥n con mi equipo local. Aunque tuve algunos problemas menores, como con ImageDataGenerator, en general fue m√°s estable que trabajar en local.

Implement√© una arquitectura similar a la vista en clase, pero yo us√©:

- 2 capas convolucionales

- 2 capas de pooling

- 1 capa densa

- Data augmentation b√°sico: zoom, horizontal_flip y rotation

- Herramientas utilizadas: TensorFlow, Keras, sklearn

Divid√≠ el dataset inicialmente en 80% para entrenamiento y 20% para pruebas.

Durante esta semana, entren√© el modelo por hasta 20 √©pocas, alcanzando un accuracy promedio de 0.5.
El modelo fue capaz de detectar al menos una clase correctamente, aunque el desempe√±o general a√∫n era muy b√°sico.


# V2 ‚Äî Semana del 7 al 11 de abril

Implement√© una versi√≥n personalizada de ColorJitter inspirada en (Ref2), con el objetivo de hacer el data augmentation m√°s robusto.
Sin embargo, el accuracy cay√≥ de 0.5 a un m√°ximo de 0.02, con fluctuaciones muy abruptas y comportamiento inestable.

Reorganic√© la distribuci√≥n del dataset siguiendo una recomendaci√≥n:

- 80% entrenamiento

- 10% validaci√≥n

- 10% prueba

### Distribuci√≥n actual del dataset:

* Total de etiquetas: 75 clases

* Im√°genes de entrenamiento: 5199

* Im√°genes de validaci√≥n: 650

* Im√°genes de prueba: 650

Encontr√© un paper relevante (Ref1) sobre clasificaci√≥n de mariposas con m√°s de 100 clases usando Inception-V3.
A√∫n estoy investigando c√≥mo implementar esa arquitectura y los tres tipos de data augmentation que utilizaron.
Por ahora, el enfoque est√° en optimizar un solo tipo de aumento antes de a√±adir m√°s complejidad.

Aument√© el n√∫mero de √©pocas de entrenamiento de 10 a 100, lo cual representa un cambio importante en el ciclo de pruebas.

### Gr√°ficos de precisi√≥n

Antes de modificar el data augmentation:

![image](https://github.com/user-attachments/assets/6af0b676-5c32-4dc0-b62a-5f6dc140547e)

Despu√©s de la modificaci√≥n agresiva:

![image](https://github.com/user-attachments/assets/e1ca6bf7-e3be-4687-8d2c-aff2bf254c59)

Con ajustes menos agresivos:

![image](https://github.com/user-attachments/assets/20704f3d-f9d4-455a-b995-f69e89f9ac38)

Para entender el desempe√±o por clase, cre√© una matriz de confusi√≥n. La primera versi√≥n gr√°fica result√≥ poco legible por la cantidad de clases, as√≠ que opt√© por un resumen textual:

![image](https://github.com/user-attachments/assets/43d431b8-1623-454e-af57-d7576e82b318)

Actualmente el modelo solo reconoce correctamente 3 clases de mariposas. Esto sugiere posibles problemas de underfitting y que el data augmentation a√∫n no est√° bien calibrado.

### Referencias

[Ref1] Paper sobre clasificaci√≥n de mariposas con m√°s de 100 clases:
https://dl.futuretechsci.org/id/eprint/73/1/9443-Article%20Text-30154-5-10-20240615.pdf

[Ref2] Paper sobre t√©cnicas avanzadas de data augmentation:
https://doi.org/10.48550/arXiv.2502.18691
