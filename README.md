# Butterfly Classification
# V1 ‚Äî Semana del 31 de marzo al 4 de abril
## Elecci√≥n del Dataset

Eleg√≠ el dataset Butterfly Image Classification disponible en Kaggle:
üîó https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification

La tem√°tica me pareci√≥ interesante y atractiva, asum√≠ que las mariposas se diferenciaban principalmente por color, lo que podr√≠a facilitar la clasificaci√≥n. Adem√°s, el dataset cuenta con buenas rese√±as de usabilidad en la plataforma.

Decid√≠ trabajar en Google Colab por la facilidad que ofrece en compatibilidad de librer√≠as y por su mayor capacidad de c√≥mputo en comparaci√≥n con mi equipo local. Aunque tuve algunos problemas menores, como con ImageDataGenerator, en general fue m√°s estable que trabajar en local.

Implement√© una arquitectura similar a la vista en clase, pero yo us√©:

- 2 capas convolucionales

- 2 capas de pooling

- 1 capa densa

- Data augmentation b√°sico: zoom, horizontal_flip y rotation

- Herramientas utilizadas: TensorFlow, Keras, sklearn

Divid√≠ el dataset inicialmente en 80% para entrenamiento y 20% para pruebas.

Durante esta semana, entren√© el modelo por hasta 20 √©pocas, alcanzando un accuracy promedio de 0.5.
El modelo fue capaz de detectar al menos una clase correctamente, aunque el desempe√±o general a√∫n era muy b√°sico.


# V2 ‚Äî Semana del 7 al 11 de abril

Implement√© una versi√≥n personalizada de ColorJitter inspirada en (Ref2), con el objetivo de hacer el data augmentation m√°s robusto.
Sin embargo, el accuracy cay√≥ de 0.5 a un m√°ximo de 0.02, con fluctuaciones muy abruptas y comportamiento inestable.

Reorganic√© la distribuci√≥n del dataset siguiendo una recomendaci√≥n:

- 80% entrenamiento

- 10% validaci√≥n

- 10% prueba

### Distribuci√≥n actual del dataset:

* Total de etiquetas: 75 clases

* Im√°genes de entrenamiento: 5199

* Im√°genes de validaci√≥n: 650

* Im√°genes de prueba: 650

Encontr√© un paper relevante (Ref1) sobre clasificaci√≥n de mariposas con m√°s de 100 clases usando Inception-V3.
A√∫n estoy investigando c√≥mo implementar esa arquitectura y los tres tipos de data augmentation que utilizaron.
Por ahora, el enfoque est√° en optimizar un solo tipo de aumento antes de a√±adir m√°s complejidad.

Aument√© el n√∫mero de √©pocas de entrenamiento de 10 a 100, lo cual representa un cambio importante en el ciclo de pruebas.

### Gr√°ficos de precisi√≥n

Antes de modificar el data augmentation:

![image](https://github.com/user-attachments/assets/6af0b676-5c32-4dc0-b62a-5f6dc140547e)

Despu√©s de la modificaci√≥n agresiva:

![image](https://github.com/user-attachments/assets/e1ca6bf7-e3be-4687-8d2c-aff2bf254c59)

Con ajustes menos agresivos:

![image](https://github.com/user-attachments/assets/20704f3d-f9d4-455a-b995-f69e89f9ac38)

Para entender el desempe√±o por clase, cre√© una matriz de confusi√≥n. La primera versi√≥n gr√°fica result√≥ poco legible por la cantidad de clases, as√≠ que opt√© por un resumen textual:

![image](https://github.com/user-attachments/assets/43d431b8-1623-454e-af57-d7576e82b318)

Actualmente el modelo solo reconoce correctamente 3 clases de mariposas. Esto sugiere posibles problemas de underfitting y que el data augmentation a√∫n no est√° bien calibrado.

### Referencias

[Ref1] Paper sobre clasificaci√≥n de mariposas con m√°s de 100 clases:
https://dl.futuretechsci.org/id/eprint/73/1/9443-Article%20Text-30154-5-10-20240615.pdf

[Ref2] Paper sobre t√©cnicas avanzadas de data augmentation:
https://doi.org/10.48550/arXiv.2502.18691
